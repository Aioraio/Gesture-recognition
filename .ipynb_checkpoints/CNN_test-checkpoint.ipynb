{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57094b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e10a1083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41960785 0.4627451  0.49803922 0.5254902  0.54509807 0.56078434\n",
      " 0.57254905 0.5882353  0.6        0.6117647  0.61960787 0.627451\n",
      " 0.6392157  0.64705884 0.62352943 0.6509804  0.65882355 0.6666667\n",
      " 0.6666667  0.67058825 0.67058825 0.67058825 0.6745098  0.67058825\n",
      " 0.67058825 0.6666667  0.6666667  0.6627451  0.43529412 0.4745098\n",
      " 0.5058824  0.5294118  0.5529412  0.5647059  0.5803922  0.5921569\n",
      " 0.6039216  0.6156863  0.627451   0.6392157  0.6431373  0.6666667\n",
      " 0.46666667 0.59607846 0.67058825 0.67058825 0.6666667  0.67058825\n",
      " 0.6745098  0.6745098  0.6745098  0.6745098  0.6745098  0.67058825\n",
      " 0.67058825 0.6666667  0.44313726 0.48235294 0.5137255  0.5372549\n",
      " 0.5568628  0.5686275  0.5882353  0.59607846 0.60784316 0.61960787\n",
      " 0.6313726  0.6392157  0.6431373  0.6745098  0.4117647  0.5568628\n",
      " 0.6666667  0.67058825 0.67058825 0.67058825 0.6745098  0.6745098\n",
      " 0.6784314  0.6784314  0.6745098  0.67058825 0.67058825 0.67058825\n",
      " 0.45490196 0.49019608 0.52156866 0.54509807 0.56078434 0.57254905\n",
      " 0.5921569  0.6        0.6117647  0.62352943 0.63529414 0.6392157\n",
      " 0.654902   0.654902   0.37254903 0.5647059  0.67058825 0.6745098\n",
      " 0.6745098  0.6745098  0.6745098  0.6745098  0.6784314  0.6784314\n",
      " 0.6784314  0.6745098  0.6745098  0.67058825 0.45882353 0.49411765\n",
      " 0.5254902  0.54901963 0.5686275  0.58431375 0.6        0.6117647\n",
      " 0.61960787 0.6313726  0.6392157  0.6431373  0.6862745  0.6117647\n",
      " 0.34117648 0.6039216  0.6745098  0.6784314  0.6784314  0.6784314\n",
      " 0.6784314  0.6784314  0.68235296 0.68235296 0.68235296 0.6784314\n",
      " 0.6745098  0.6745098  0.46666667 0.5019608  0.53333336 0.5568628\n",
      " 0.57254905 0.5882353  0.6        0.6117647  0.62352943 0.6392157\n",
      " 0.64705884 0.6431373  0.72156864 0.5803922  0.34901962 0.6431373\n",
      " 0.6745098  0.68235296 0.68235296 0.68235296 0.68235296 0.6862745\n",
      " 0.6862745  0.68235296 0.6862745  0.68235296 0.6784314  0.6784314\n",
      " 0.47843137 0.50980395 0.5411765  0.56078434 0.5764706  0.5882353\n",
      " 0.6039216  0.61960787 0.63529414 0.64705884 0.6509804  0.6745098\n",
      " 0.70980394 0.5019608  0.36862746 0.6666667  0.6784314  0.6862745\n",
      " 0.68235296 0.6862745  0.6901961  0.69411767 0.69411767 0.69411767\n",
      " 0.69411767 0.6862745  0.6862745  0.68235296 0.47843137 0.5176471\n",
      " 0.54509807 0.5686275  0.58431375 0.59607846 0.6117647  0.627451\n",
      " 0.6392157  0.64705884 0.6509804  0.70980394 0.6745098  0.40392157\n",
      " 0.44313726 0.6862745  0.6901961  0.69803923 0.69803923 0.7019608\n",
      " 0.7019608  0.7019608  0.7019608  0.69803923 0.7019608  0.69411767\n",
      " 0.6862745  0.68235296 0.49019608 0.5254902  0.5529412  0.5764706\n",
      " 0.5882353  0.6        0.6156863  0.6313726  0.6431373  0.654902\n",
      " 0.65882355 0.72156864 0.7019608  0.45490196 0.49411765 0.64705884\n",
      " 0.6901961  0.7019608  0.7058824  0.7058824  0.70980394 0.7058824\n",
      " 0.7058824  0.7058824  0.7019608  0.69803923 0.69411767 0.6901961\n",
      " 0.5019608  0.5294118  0.5568628  0.5803922  0.59607846 0.6039216\n",
      " 0.61960787 0.63529414 0.64705884 0.65882355 0.6666667  0.73333335\n",
      " 0.7058824  0.6117647  0.6313726  0.4862745  0.56078434 0.7019608\n",
      " 0.69803923 0.69803923 0.70980394 0.7137255  0.70980394 0.7058824\n",
      " 0.70980394 0.7058824  0.7019608  0.7019608  0.5058824  0.53333336\n",
      " 0.5647059  0.5882353  0.6        0.60784316 0.62352943 0.6392157\n",
      " 0.6509804  0.6627451  0.6745098  0.73333335 0.72156864 0.6\n",
      " 0.4        0.45882353 0.43137255 0.6862745  0.6627451  0.6039216\n",
      " 0.7137255  0.7176471  0.7176471  0.7137255  0.7137255  0.70980394\n",
      " 0.70980394 0.7019608  0.5137255  0.5411765  0.5686275  0.5882353\n",
      " 0.60784316 0.6156863  0.6313726  0.64705884 0.65882355 0.68235296\n",
      " 0.74509805 0.7411765  0.6862745  0.57254905 0.36862746 0.38039216\n",
      " 0.44313726 0.5921569  0.61960787 0.5058824  0.72156864 0.72156864\n",
      " 0.72156864 0.72156864 0.7176471  0.7176471  0.7137255  0.7058824\n",
      " 0.5137255  0.54509807 0.57254905 0.5921569  0.60784316 0.62352943\n",
      " 0.6392157  0.654902   0.6862745  0.7137255  0.7019608  0.67058825\n",
      " 0.62352943 0.44705883 0.4        0.34901962 0.4745098  0.53333336\n",
      " 0.53333336 0.3764706  0.6745098  0.7294118  0.7294118  0.7254902\n",
      " 0.7254902  0.72156864 0.7137255  0.70980394 0.5137255  0.54901963\n",
      " 0.5764706  0.6039216  0.6156863  0.627451   0.6431373  0.7019608\n",
      " 0.7294118  0.7490196  0.73333335 0.7058824  0.6156863  0.39215687\n",
      " 0.34509805 0.32941177 0.42352942 0.43529412 0.49411765 0.3529412\n",
      " 0.47058824 0.7294118  0.73333335 0.73333335 0.7294118  0.7254902\n",
      " 0.72156864 0.7137255  0.52156866 0.5529412  0.58431375 0.60784316\n",
      " 0.61960787 0.627451   0.68235296 0.7882353  0.7411765  0.64705884\n",
      " 0.5921569  0.56078434 0.57254905 0.47058824 0.34117648 0.30588236\n",
      " 0.34117648 0.29803923 0.42352942 0.38431373 0.3764706  0.70980394\n",
      " 0.7372549  0.73333335 0.7294118  0.7294118  0.7254902  0.7176471\n",
      " 0.52156866 0.5529412  0.5882353  0.6117647  0.627451   0.6313726\n",
      " 0.7019608  0.77254903 0.68235296 0.5294118  0.3882353  0.28235295\n",
      " 0.37254903 0.5254902  0.38039216 0.28235295 0.2901961  0.26666668\n",
      " 0.45490196 0.4117647  0.42352942 0.73333335 0.7411765  0.73333335\n",
      " 0.73333335 0.7294118  0.7294118  0.7254902  0.5254902  0.56078434\n",
      " 0.5921569  0.6117647  0.6313726  0.6392157  0.7019608  0.7607843\n",
      " 0.6117647  0.43137255 0.2901961  0.16470589 0.20392157 0.54509807\n",
      " 0.36862746 0.2627451  0.29411766 0.29411766 0.4627451  0.41568628\n",
      " 0.5058824  0.7411765  0.7490196  0.74509805 0.7372549  0.7372549\n",
      " 0.73333335 0.7294118  0.5294118  0.5647059  0.59607846 0.61960787\n",
      " 0.6392157  0.6392157  0.69411767 0.75686276 0.6313726  0.47843137\n",
      " 0.32941177 0.16862746 0.2784314  0.5254902  0.31764707 0.22352941\n",
      " 0.2784314  0.34509805 0.4392157  0.38431373 0.6156863  0.75686276\n",
      " 0.75686276 0.7529412  0.74509805 0.74509805 0.7411765  0.7372549\n",
      " 0.53333336 0.5647059  0.59607846 0.61960787 0.63529414 0.6392157\n",
      " 0.6901961  0.7529412  0.6431373  0.5019608  0.38431373 0.24313726\n",
      " 0.23529412 0.39215687 0.2784314  0.29803923 0.3764706  0.39607844\n",
      " 0.4117647  0.37254903 0.68235296 0.7647059  0.7607843  0.7607843\n",
      " 0.7607843  0.75686276 0.7490196  0.74509805 0.5372549  0.5686275\n",
      " 0.59607846 0.62352943 0.6431373  0.64705884 0.69803923 0.7490196\n",
      " 0.6431373  0.5294118  0.44313726 0.32156864 0.23137255 0.34117648\n",
      " 0.38431373 0.43529412 0.47058824 0.42352942 0.38039216 0.42352942\n",
      " 0.74509805 0.76862746 0.7647059  0.7647059  0.7607843  0.75686276\n",
      " 0.75686276 0.7529412  0.54509807 0.57254905 0.6039216  0.627451\n",
      " 0.6431373  0.64705884 0.6862745  0.7294118  0.6392157  0.54509807\n",
      " 0.4392157  0.33333334 0.2627451  0.4        0.49411765 0.52156866\n",
      " 0.49411765 0.4117647  0.40784314 0.6901961  0.77254903 0.7764706\n",
      " 0.77254903 0.76862746 0.7647059  0.7647059  0.7607843  0.75686276\n",
      " 0.5411765  0.5764706  0.60784316 0.6313726  0.64705884 0.654902\n",
      " 0.6745098  0.7294118  0.6392157  0.5372549  0.41960785 0.34117648\n",
      " 0.29803923 0.41568628 0.47843137 0.49019608 0.45882353 0.3764706\n",
      " 0.6117647  0.78039217 0.78039217 0.78431374 0.7764706  0.76862746\n",
      " 0.76862746 0.7647059  0.7647059  0.7607843  0.54509807 0.5803922\n",
      " 0.6117647  0.6392157  0.6509804  0.65882355 0.6745098  0.7058824\n",
      " 0.61960787 0.5137255  0.42352942 0.3882353  0.3372549  0.42352942\n",
      " 0.4627451  0.45490196 0.40392157 0.41960785 0.7490196  0.7921569\n",
      " 0.7882353  0.78431374 0.78431374 0.78431374 0.78039217 0.77254903\n",
      " 0.7764706  0.76862746 0.54901963 0.58431375 0.6156863  0.6431373\n",
      " 0.65882355 0.654902   0.69411767 0.69803923 0.60784316 0.5137255\n",
      " 0.4627451  0.4117647  0.34117648 0.39215687 0.41568628 0.39215687\n",
      " 0.3764706  0.6431373  0.7921569  0.7921569  0.7921569  0.7921569\n",
      " 0.7921569  0.7882353  0.78431374 0.78039217 0.78039217 0.7764706\n",
      " 0.54901963 0.5882353  0.6156863  0.64705884 0.654902   0.6666667\n",
      " 0.70980394 0.6862745  0.59607846 0.50980395 0.4509804  0.38431373\n",
      " 0.32156864 0.33333334 0.3529412  0.3882353  0.64705884 0.7921569\n",
      " 0.79607844 0.8        0.79607844 0.79607844 0.7921569  0.7921569\n",
      " 0.7882353  0.7882353  0.78431374 0.78431374 0.5568628  0.5882353\n",
      " 0.62352943 0.64705884 0.6666667  0.7490196  0.6784314  0.6156863\n",
      " 0.5647059  0.46666667 0.38039216 0.32941177 0.30980393 0.30980393\n",
      " 0.35686275 0.6745098  0.7921569  0.79607844 0.79607844 0.8039216\n",
      " 0.8        0.8        0.8        0.79607844 0.7921569  0.7921569\n",
      " 0.7882353  0.78431374 0.5568628  0.5921569  0.627451   0.64705884\n",
      " 0.7372549  0.74509805 0.73333335 0.5882353  0.46666667 0.42745098\n",
      " 0.33333334 0.30980393 0.30980393 0.30588236 0.5372549  0.79607844\n",
      " 0.8039216  0.80784315 0.80784315 0.8117647  0.8117647  0.80784315\n",
      " 0.80784315 0.8        0.8039216  0.8        0.79607844 0.7921569\n",
      " 0.5568628  0.5921569  0.627451   0.6745098  0.76862746 0.7372549\n",
      " 0.7372549  0.74509805 0.5294118  0.3764706  0.3372549  0.3019608\n",
      " 0.3019608  0.30980393 0.6901961  0.8039216  0.8117647  0.8117647\n",
      " 0.8117647  0.8117647  0.8117647  0.8117647  0.80784315 0.80784315\n",
      " 0.80784315 0.8        0.79607844 0.7921569 ]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('E:/MyProject/GR/dataset/archive/sign_mnist_train.csv',dtype=np.float32)\n",
    "test = pd.read_csv('E:/MyProject/GR/dataset/archive/sign_mnist_test.csv',dtype=np.float32)\n",
    "\n",
    "\n",
    "train_y = train.label.values       #label\n",
    "train_x = train.loc[:,train.columns!= 'label'].values / 255     #图片数据\n",
    "print(train_x[0]) \n",
    "test_y = test.label.values\n",
    "test_x = test.loc[:,test.columns!= 'label'].values / 255\n",
    "\n",
    "\n",
    "\n",
    "train_x = torch.from_numpy(train_x)          #转换成tensor\n",
    "train_y = torch.from_numpy(train_y).type(torch.LongTensor)    #转换成Longtensor，交叉熵损失函数的label需要long类型的数据\n",
    "\n",
    "test_x = torch.from_numpy(test_x)\n",
    "test_y = torch.from_numpy(test_y).type(torch.LongTensor)\n",
    "\n",
    "\n",
    "train = TensorDataset(train_x,train_y)     #转换成Dataset，类似于TensorFlow的from_tensor_slices\n",
    "test = TensorDataset(test_x,test_y)\n",
    "\n",
    "train_loader = DataLoader(train,batch_size=100,shuffle=False,drop_last=True)  # 构造DataLoader\n",
    "test_loader = DataLoader(test,batch_size=100,shuffle=False,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67cd9ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layers1 = nn.Sequential(\n",
    "            nn.Conv2d(1,16,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.layers2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.layers3 = nn.Sequential(\n",
    "            nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layers4 = nn.Sequential(\n",
    "            nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(7*7*128,1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024,100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100,26)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers1(x)\n",
    "        x = self.layers2(x)\n",
    "        x = self.layers3(x)\n",
    "        x = self.layers4(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d30d1282",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "error = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(cnn.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32973d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda'if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "463ffebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae66b5b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "accuracy: 0.06567205800334634\n",
      "accuracy: 0.44492470719464583\n",
      "accuracy: 0.7463747908533185\n",
      "accuracy: 0.8980758505298383\n",
      "accuracy: 0.9375348577802566\n",
      "accuracy: 0.9419966536530954\n",
      "epochs: 1\n",
      "accuracy: 0.9376742889012828\n",
      "accuracy: 0.9446458449525934\n",
      "accuracy: 0.9440881204684886\n",
      "accuracy: 0.9447852760736196\n",
      "accuracy: 0.9449247071946458\n",
      "accuracy: 0.9457612939208031\n",
      "epochs: 2\n",
      "accuracy: 0.9411600669269381\n",
      "accuracy: 0.9468767428890128\n",
      "accuracy: 0.9445064138315672\n",
      "accuracy: 0.9459007250418293\n",
      "accuracy: 0.9454824316787507\n",
      "accuracy: 0.9457612939208031\n",
      "epochs: 3\n",
      "accuracy: 0.9432515337423313\n",
      "accuracy: 0.947016174010039\n",
      "accuracy: 0.9449247071946458\n",
      "accuracy: 0.946319018404908\n",
      "accuracy: 0.946319018404908\n",
      "accuracy: 0.9456218627997769\n",
      "epochs: 4\n",
      "accuracy: 0.9440881204684886\n",
      "accuracy: 0.9468767428890128\n",
      "accuracy: 0.9456218627997769\n",
      "accuracy: 0.946319018404908\n",
      "accuracy: 0.9471556051310652\n",
      "accuracy: 0.9453430005577245\n",
      "epochs: 5\n",
      "accuracy: 0.9446458449525934\n",
      "accuracy: 0.9472950362520914\n",
      "accuracy: 0.9461795872838817\n",
      "accuracy: 0.9467373117679866\n",
      "accuracy: 0.9468767428890128\n",
      "accuracy: 0.9459007250418293\n",
      "epochs: 6\n",
      "accuracy: 0.9452035694366983\n",
      "accuracy: 0.9474344673731177\n",
      "accuracy: 0.946319018404908\n",
      "accuracy: 0.9471556051310652\n",
      "accuracy: 0.9475738984941439\n",
      "accuracy: 0.9464584495259342\n",
      "epochs: 7\n",
      "accuracy: 0.9452035694366983\n",
      "accuracy: 0.9479921918572225\n",
      "accuracy: 0.9468767428890128\n",
      "accuracy: 0.9472950362520914\n",
      "accuracy: 0.9475738984941439\n",
      "accuracy: 0.9471556051310652\n",
      "epochs: 8\n",
      "accuracy: 0.9457612939208031\n",
      "accuracy: 0.9479921918572225\n",
      "accuracy: 0.9472950362520914\n",
      "accuracy: 0.9477133296151701\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.9478527607361963\n",
      "epochs: 9\n",
      "accuracy: 0.946319018404908\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.9474344673731177\n",
      "accuracy: 0.9477133296151701\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.9481316229782487\n",
      "epochs: 10\n",
      "accuracy: 0.9471556051310652\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.9477133296151701\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.9479921918572225\n",
      "accuracy: 0.9479921918572225\n",
      "epochs: 11\n",
      "accuracy: 0.9474344673731177\n",
      "accuracy: 0.9482710540992749\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.9481316229782487\n",
      "accuracy: 0.9482710540992749\n",
      "accuracy: 0.9481316229782487\n",
      "epochs: 12\n",
      "accuracy: 0.9474344673731177\n",
      "accuracy: 0.9485499163413273\n",
      "accuracy: 0.9482710540992749\n",
      "accuracy: 0.9482710540992749\n",
      "accuracy: 0.9481316229782487\n",
      "accuracy: 0.9484104852203011\n",
      "epochs: 13\n",
      "accuracy: 0.9474344673731177\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9485499163413273\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9482710540992749\n",
      "epochs: 14\n",
      "accuracy: 0.9475738984941439\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9484104852203011\n",
      "accuracy: 0.9479921918572225\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9482710540992749\n",
      "epochs: 15\n",
      "accuracy: 0.9475738984941439\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9482710540992749\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9485499163413273\n",
      "epochs: 16\n",
      "accuracy: 0.9475738984941439\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9486893474623536\n",
      "accuracy: 0.9479921918572225\n",
      "accuracy: 0.9486893474623536\n",
      "accuracy: 0.9484104852203011\n",
      "epochs: 17\n",
      "accuracy: 0.9472950362520914\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9485499163413273\n",
      "accuracy: 0.9477133296151701\n",
      "accuracy: 0.9486893474623536\n",
      "accuracy: 0.9482710540992749\n",
      "epochs: 18\n",
      "accuracy: 0.9472950362520914\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9485499163413273\n",
      "accuracy: 0.9475738984941439\n",
      "accuracy: 0.9486893474623536\n",
      "accuracy: 0.9482710540992749\n",
      "epochs: 19\n",
      "accuracy: 0.9477133296151701\n",
      "accuracy: 0.9486893474623536\n",
      "accuracy: 0.9485499163413273\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9484104852203011\n",
      "epochs: 20\n",
      "accuracy: 0.9477133296151701\n",
      "accuracy: 0.9486893474623536\n",
      "accuracy: 0.9486893474623536\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9484104852203011\n",
      "epochs: 21\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9486893474623536\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9482710540992749\n",
      "epochs: 22\n",
      "accuracy: 0.9479921918572225\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9485499163413273\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9482710540992749\n",
      "epochs: 23\n",
      "accuracy: 0.9479921918572225\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9485499163413273\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9484104852203011\n",
      "epochs: 24\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.9485499163413273\n",
      "accuracy: 0.9486893474623536\n",
      "accuracy: 0.9481316229782487\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9485499163413273\n",
      "epochs: 25\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.9484104852203011\n",
      "accuracy: 0.9485499163413273\n",
      "accuracy: 0.9482710540992749\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9485499163413273\n",
      "epochs: 26\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.9485499163413273\n",
      "accuracy: 0.9485499163413273\n",
      "accuracy: 0.9481316229782487\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9485499163413273\n",
      "epochs: 27\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9486893474623536\n",
      "accuracy: 0.9481316229782487\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9484104852203011\n",
      "epochs: 28\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9486893474623536\n",
      "accuracy: 0.9481316229782487\n",
      "accuracy: 0.9486893474623536\n",
      "accuracy: 0.9485499163413273\n",
      "epochs: 29\n",
      "accuracy: 0.9478527607361963\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9481316229782487\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9486893474623536\n",
      "epochs: 30\n",
      "accuracy: 0.9482710540992749\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9484104852203011\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9486893474623536\n",
      "epochs: 31\n",
      "accuracy: 0.9484104852203011\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9485499163413273\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9488287785833798\n",
      "epochs: 32\n",
      "accuracy: 0.9484104852203011\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9484104852203011\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9488287785833798\n",
      "epochs: 33\n",
      "accuracy: 0.9484104852203011\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9486893474623536\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9486893474623536\n",
      "epochs: 34\n",
      "accuracy: 0.9484104852203011\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9486893474623536\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9488287785833798\n",
      "epochs: 35\n",
      "accuracy: 0.9484104852203011\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9488287785833798\n",
      "epochs: 36\n",
      "accuracy: 0.9485499163413273\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9491076408254322\n",
      "epochs: 37\n",
      "accuracy: 0.9484104852203011\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.948968209704406\n",
      "epochs: 38\n",
      "accuracy: 0.9484104852203011\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9491076408254322\n",
      "epochs: 39\n",
      "accuracy: 0.9484104852203011\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.948968209704406\n",
      "epochs: 40\n",
      "accuracy: 0.9485499163413273\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.948968209704406\n",
      "epochs: 41\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.948968209704406\n",
      "epochs: 42\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9492470719464584\n",
      "epochs: 43\n",
      "accuracy: 0.9488287785833798\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9492470719464584\n",
      "epochs: 44\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9492470719464584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 45\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9491076408254322\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 46\n",
      "accuracy: 0.948968209704406\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 47\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 48\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 49\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 50\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 51\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 52\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 53\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 54\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9492470719464584\n",
      "epochs: 55\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9492470719464584\n",
      "epochs: 56\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9492470719464584\n",
      "epochs: 57\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9492470719464584\n",
      "epochs: 58\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9492470719464584\n",
      "epochs: 59\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 60\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 61\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 62\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9492470719464584\n",
      "epochs: 63\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9492470719464584\n",
      "epochs: 64\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9492470719464584\n",
      "epochs: 65\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9492470719464584\n",
      "epochs: 66\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 67\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 68\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 69\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 70\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 71\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 72\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 73\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 74\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 75\n",
      "accuracy: 0.9492470719464584\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 76\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9493865030674846\n",
      "epochs: 77\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 78\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 79\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9499442275515895\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 80\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9499442275515895\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 81\n",
      "accuracy: 0.9493865030674846\n",
      "accuracy: 0.9499442275515895\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 82\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 83\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9495259341885108\n",
      "epochs: 84\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "epochs: 85\n",
      "accuracy: 0.9495259341885108\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9499442275515895\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "epochs: 86\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9499442275515895\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "epochs: 87\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9499442275515895\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "epochs: 88\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "epochs: 89\n",
      "accuracy: 0.949665365309537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "epochs: 90\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.949665365309537\n",
      "epochs: 91\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.949665365309537\n",
      "epochs: 92\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.949665365309537\n",
      "epochs: 93\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "epochs: 94\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "epochs: 95\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "epochs: 96\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "epochs: 97\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.949665365309537\n",
      "epochs: 98\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "epochs: 99\n",
      "accuracy: 0.949665365309537\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9499442275515895\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n",
      "accuracy: 0.9498047964305633\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(100):\n",
    "    print('epochs:',epochs)\n",
    "    for i ,(img,label) in enumerate(train_loader):\n",
    "        img = img.view(100,1,28,28)\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        optimizer.zero_grad()\n",
    "        output = cnn(img)\n",
    "\n",
    "        loss = error(output,label)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if i %50 == 0:\n",
    "            accuracy = 0\n",
    "            for x,y in test_loader:\n",
    "\n",
    "                x = x.view(100,1,28,28)\n",
    "                x = x.cuda()\n",
    "                x = Variable(x)\n",
    "\n",
    "\n",
    "                out = cnn(x)\n",
    "                pre = torch.max(out.data,1)[1]\n",
    "                \n",
    "                y = y.cuda()\n",
    "                accuracy += (pre == y).sum()\n",
    "\n",
    "            print('accuracy:',accuracy.item()/(7172))\n",
    "            if(accuracy.item()/(7172)>0.975):\n",
    "                torch.save(cnn.state_dict(),'E:/MyProject/GR/dataset/archive/abcd.pth')\n",
    "            if(accuracy.item()/7172 > 0.983):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b86815fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9830631943179748\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for x,y in test_loader:\n",
    "    \n",
    "    x = x.view(100,1,28,28)\n",
    "    x = x.cuda()\n",
    "    x = Variable(x)\n",
    "\n",
    "\n",
    "    out = cnn(x)\n",
    "    pre = torch.max(out.data,1)[1]\n",
    "\n",
    "    y = y.cuda()\n",
    "    accuracy += (pre == y).sum()\n",
    "print('accuracy:',accuracy.item()/(5491))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0aba8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(),'E:/MyProject/GR/dataset/archive/cnn_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f015a60",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_loader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "test_loader[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53dae00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "for x,y in test_loader:\n",
    "    \n",
    "    print(x.shape)\n",
    "    \n",
    "    \n",
    "    x = x.view(100,1,28,28)\n",
    "    print(x.shape)\n",
    "    x = x.cuda()\n",
    "    \n",
    "    x = Variable(x)\n",
    "    print(x.shape)\n",
    "    \n",
    "    if n == 1:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671de067",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\t# 导入网络结构\n",
    "cnn.load_state_dict(torch.load('E:/MyProject/GR/dataset/archive/cnn_1.pth')) # 导入网络的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e88cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf126a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('E:/MyProject/GR/dataset/test_0.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img,(28,28))\n",
    "img = img/255\n",
    "img = torch.from_numpy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62937da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = img\n",
    "x = x.to(torch.float32)\n",
    "x = x.view(1,1,28,28)\n",
    "x = Variable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5d7587a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = cnn(x)\n",
    "pre = torch.max(out.data,1)[1]\n",
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c0a8af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
